# sceneforged — Converter & Library Manager

Claude Code reference. Sceneforged is the media library manager. It owns file import, metadata, the conversion pipeline, and the library database. The player (sceneforged-player) will be merged into it later. The converter is sceneforged's only encoding path — there is no live transcoding.

---

## Architecture Change: Dynamic Profiles

The previous spec assumed every item gets two files (Profile A + Profile B). In practice, the vast majority of a library won't have archival 4K HDR remuxes. Most items will have one file — either the original source or a transcoded universal copy. The system must work correctly with one, two, or even zero local files per item.

### What "profiles" actually mean now

**Source file** — whatever the user has. Could be an MKV remux, an MP4 download, a legacy AVI. This is the file the scanner discovers. It is never modified or re-encoded. It stays where the user put it.

**Universal file** — a Profile B MP4 generated by sceneforged's converter. This is what the player serves over HLS. It exists only if the converter has run, or if the source file already satisfies the Profile B contract (H.264 MP4 with faststart and regular keyframes).

### When each exists

| Scenario | Source file | Universal file | Notes |
|----------|------------|----------------|-------|
| Fresh import, no conversion | ✓ | ✗ | Player serves source via direct stream (range requests). No HLS. |
| After conversion completes | ✓ | ✓ | Player prefers universal for HLS. Source available for direct download. |
| Source already meets Profile B spec | ✓ | ✗ (source IS universal) | Player detects this at scan time. No conversion needed. |
| User deletes source after conversion | ✗ | ✓ | Fully valid. Universal file is self-contained. |
| Online-acquired pair (e.g. 4K + 1080p) | ✓ (4K) | ✓ (1080p) | Both imported directly. No conversion. |

### Source qualification check

At scan time, sceneforged checks whether the source file already satisfies the universal profile contract:

```rust
struct SourceQualification {
    serves_as_universal: bool,      // Can the player HLS-serve this directly?
    needs_conversion: bool,         // Should we queue a conversion job?
    conversion_reason: Option<String>,
}

fn qualify_source(probe: &MediaProbe) -> SourceQualification {
    let dominated = true
        && probe.container == Container::Mp4
        && probe.video_codec == VideoCodec::H264
        && probe.has_faststart                     // moov before mdat
        && probe.keyframe_interval_secs <= 3.0     // regular keyframes
        && probe.video_tracks == 1
        && probe.audio_tracks == 1
        && probe.audio_codec == AudioCodec::Aac;

    SourceQualification {
        serves_as_universal: dominated,
        needs_conversion: !dominated,
        conversion_reason: if dominated { None } else {
            Some(describe_why_not(probe))
        },
    }
}
```

If the source qualifies, the player builds its segment map from the source file directly — no conversion, no second file on disk.

---

## Rust Library Landscape for Encoding

Every component of the pipeline was evaluated for whether a Rust-native solution exists and whether it's production-ready.

### Container Demuxing (reading input files)

| Library | What it does | Pure Rust | Status | Verdict |
|---------|-------------|-----------|--------|---------|
| `symphonia` | Demux MKV, MP4, OGG, WAV + decode FLAC, AAC, MP3, Vorbis | Yes | Active, mature | **Use for audio decode + container probe** |
| `matroska-demuxer` | Demux MKV/WebM, frame-level access | Yes | Maintained | Good for MKV-specific work |
| sf-media (ours) | MP4 moov parsing, MKV EBML cues | Yes | Player already builds this | **Reuse for Profile B verification** |

symphonia can demux both MKV and MP4 and decode the audio codecs we care about (AAC, FLAC, Vorbis). It provides packet-level access to video tracks (compressed NALUs) which we can feed to a video decoder.

### Video Decoding (reading compressed video frames)

| Library | Codecs | Pure Rust | Speed | Verdict |
|---------|--------|-----------|-------|---------|
| `openh264` | H.264 (Baseline only for decode) | No (C via cc) | Good | **Not sufficient** — many sources are High/Main profile |
| `rav1d` | AV1 | Yes (Rust port of dav1d) | ~95% of dav1d | Excellent for AV1 sources |
| `ffmpeg-the-third` | All (via libavcodec) | No (FFmpeg FFI) | Reference speed | **Required for HEVC, H.264 High, VP9** |

**Reality: there is no pure Rust library that can decode H.264 High Profile or HEVC.** OpenH264's decoder only handles Baseline/Constrained Baseline reliably. For a media server that must handle arbitrary input, FFmpeg's libavcodec is unavoidable for the video decode step.

### Video Encoding (writing H.264 output)

| Library | Codec | Profile support | Pure Rust | Verdict |
|---------|-------|----------------|-----------|---------|
| `openh264` | H.264 | **Baseline only** | No (C via cc) | **Not usable** — we need High Profile |
| `x264` crate | H.264 | All (via libx264) | No (C FFI) | Unmaintained (last update 2022) |
| `ffmpeg-the-third` | H.264 via libx264 | All | No (FFmpeg FFI) | **Best option** — production-quality encoding |
| `rav1e` | AV1 | All | Yes | Too slow for a full library transcode |

**Reality: H.264 High Profile encoding requires libx264.** There is no pure Rust H.264 encoder that supports High Profile, B-frames, or CRF rate control. OpenH264 is Baseline-only and produces significantly worse quality at the same bitrate. The `x264` crate wraps libx264 but hasn't been updated in years.

### Audio Encoding

| Library | Codec | Pure Rust | Verdict |
|---------|-------|-----------|---------|
| `fdk-aac` | AAC-LC, HE-AAC | No (C FFI to libfdk-aac) | **Best quality AAC encoder available** |
| `ffmpeg-the-third` | AAC via FFmpeg's native encoder | No (FFmpeg FFI) | Good enough, simpler dependency |
| symphonia | Decode only | Yes | No encoding support |

If we're already linking FFmpeg for video, its built-in AAC encoder is adequate (and avoids the fdk-aac patent/license complexity).

### MP4 Muxing (writing output container)

| Library | Features | Pure Rust | Verdict |
|---------|----------|-----------|---------|
| `muxide` | MP4 mux, faststart, fMP4, H.264/H.265/AV1/AAC/Opus | Yes | **Excellent** — could replace libavformat for output |
| `mp4e` | Basic MP4 mux | Yes | Simpler but less mature |
| `ffmpeg-the-third` | Full muxing via libavformat | No | Already available if we link FFmpeg |

muxide is notable — pure Rust, supports faststart, fMP4 segments, and all the codecs we need. If we wanted to minimize our FFmpeg surface area, we could decode+encode with FFmpeg but mux with muxide. In practice, using FFmpeg's muxer is simpler since we already depend on it for the codec work.

### Video Scaling / Colour Conversion

| Library | What | Pure Rust | SIMD | Verdict |
|---------|------|-----------|------|---------|
| `yuv` | YUV ↔ RGB, all planar formats, 10/12-bit | Yes | AVX-512, AVX2, SSE, NEON | **Excellent for colour space work** |
| `pic-scale` | Image resize (Lanczos, bilinear, etc.) | Yes | AVX2, SSE, NEON | Good for scaling, operates on RGB |
| `fast_image_resize` | Image resize | Yes | SIMD | Alternative to pic-scale |
| `ffmpeg-the-third` | swscale (resize + colour convert in one) | No | Heavy SIMD | The standard approach, already linked |

The `yuv` crate is impressively fast (matches or beats libyuv) and handles 10-bit HDR source formats natively. However, FFmpeg's swscale does scale + colour convert + pixel format change in a single fused operation, which is simpler to pipeline.

### HDR → SDR Tone Mapping

| Library | Method | Pure Rust | Verdict |
|---------|--------|-----------|---------|
| `gainforge` | BT.2020 PQ → sRGB, Rec.2408 algorithm | Yes | **Works**, but per-image, not video-optimised |
| FFmpeg `zscale` filter | PQ/HLG → BT.709 via zimg | No | Battle-tested for video |
| FFmpeg `libplacebo` filter | GPU tone mapping, Dolby Vision aware | No | Best quality for DV sources |

gainforge could theoretically be used frame-by-frame, but it operates on decoded RGB images and adds decode→RGB→tonemap→YUV→encode round-trips. FFmpeg's filter graph does this in a single pass through the YUV pipeline, which is significantly faster.

### Media Probing (ffprobe replacement)

| Library | What | Pure Rust | Verdict |
|---------|------|-----------|---------|
| `symphonia` | Format/codec detection, stream enumeration | Yes | **Can replace ffprobe for most metadata** |
| sf-media (ours) | MP4 box walking, MKV EBML parsing | Yes | Already built for the player |
| `ffprobe` subprocess | Full probe | N/A | Reliable fallback |

For basic probing (container, codecs, duration, resolution, HDR detection), we can use symphonia + our own sf-media parser and avoid shelling out to ffprobe entirely. This is worthwhile because probing runs at scan time for every file, not just files being converted.

### Verdict: Hybrid Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     sceneforged                              │
│                                                              │
│  ┌──────────────────────────────┐  ┌──────────────────────┐ │
│  │        Pure Rust              │  │  FFmpeg (linked)      │ │
│  │                               │  │                       │ │
│  │  • Container probe (sf-media) │  │  • Video decode       │ │
│  │  • Symphonia (audio decode,   │  │    (libavcodec)       │ │
│  │    metadata, stream enum)     │  │  • Video encode       │ │
│  │  • Source qualification       │  │    (libx264 via       │ │
│  │  • Segment map building       │  │     libavcodec)       │ │
│  │  • fMP4 serialisation         │  │  • Audio decode/      │ │
│  │  • HLS playlist generation    │  │    encode (if not     │ │
│  │  • Profile B verification     │  │    using symphonia)   │ │
│  │  • Database, API, scanner     │  │  • swscale (resize +  │ │
│  │                               │  │    colour convert)    │ │
│  └──────────────────────────────┘  │  • Tone mapping        │ │
│                                     │    (zscale/libplacebo) │ │
│                                     │  • Muxing (faststart)  │ │
│                                     └──────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

The **player hot path** (serving) remains pure Rust with zero FFmpeg dependency. FFmpeg is a build/link-time dependency of the **converter** only. The converter links `ffmpeg-the-third` (safe Rust bindings to libavcodec/libavformat/libavfilter/libswscale).

---

## ffmpeg-the-third Integration

`ffmpeg-the-third` is the actively maintained fork of the Rust FFmpeg bindings. It provides safe wrappers around the libav* family.

### Dependency

```toml
[dependencies]
ffmpeg-the-third = "2"   # Links against system FFmpeg ≥ 5.0

# For static linking (bundles FFmpeg):
# ffmpeg-the-third = { version = "2", features = ["static"] }
```

### Transcoding Pipeline (in-process, no subprocess)

```rust
use ffmpeg_the_third as ffmpeg;
use ffmpeg::{codec, decoder, encoder, format, frame, media, Rational};

struct TranscodeJob {
    input_path: PathBuf,
    output_path: PathBuf,
    source: MediaProbe,         // Our pre-computed source analysis
    config: ConversionConfig,
    progress_tx: watch::Sender<f32>,
}

impl TranscodeJob {
    fn run(&self) -> Result<()> {
        ffmpeg::init()?;

        let mut ictx = format::input(&self.input_path)?;
        let mut octx = format::output(&self.output_path)?;

        // Find best video + audio streams
        let video_stream = ictx.streams().best(media::Type::Video)
            .ok_or(anyhow!("no video stream"))?;
        let audio_stream = ictx.streams().best(media::Type::Audio)
            .ok_or(anyhow("no audio stream"))?;

        // Set up video decoder
        let video_decoder = codec::context::Context::from_parameters(
            video_stream.parameters()
        )?.decoder().video()?;

        // Set up video encoder (H.264 High Profile)
        let x264 = encoder::find(codec::Id::H264)
            .ok_or(anyhow!("libx264 not available"))?;
        let mut video_ost = octx.add_stream(x264)?;
        let mut video_encoder = codec::context::Context::new_with_codec(x264)
            .encoder().video()?;

        let gop = (self.source.fps * 2.0).round() as i32;
        video_encoder.set_width(self.target_width());
        video_encoder.set_height(self.target_height());
        video_encoder.set_format(format::Pixel::YUV420P);
        video_encoder.set_time_base(video_stream.time_base());
        video_encoder.set_gop(gop as u32);
        // ... set profile, level, CRF via codec options dictionary

        // Set up audio encoder (AAC)
        let aac = encoder::find(codec::Id::AAC).unwrap();
        let mut audio_ost = octx.add_stream(aac)?;
        let mut audio_encoder = codec::context::Context::new_with_codec(aac)
            .encoder().audio()?;
        audio_encoder.set_rate(48000);
        audio_encoder.set_channels(2);
        // ... set bitrate 256k

        // Open encoders, write header
        let video_encoder = video_encoder.open_as_with(x264, x264_opts)?;
        let audio_encoder = audio_encoder.open_as(aac)?;
        octx.write_header()?;

        // Main decode → encode loop
        let total_duration = ictx.duration() as f64 / f64::from(ffmpeg::ffi::AV_TIME_BASE);
        for (stream, packet) in ictx.packets() {
            match stream.parameters().medium() {
                media::Type::Video => {
                    // decode → filter (scale, tonemap) → encode
                }
                media::Type::Audio => {
                    // decode → resample → encode
                }
                _ => {}
            }
            // Report progress
            let current = packet.dts().unwrap_or(0) as f64
                * f64::from(stream.time_base());
            let _ = self.progress_tx.send(
                (current / total_duration * 100.0).min(100.0) as f32
            );
        }

        // Flush encoders, write trailer
        octx.write_trailer()?;

        // Post-process: ensure faststart (moov before mdat)
        // ffmpeg-the-third with +faststart movflag handles this
        Ok(())
    }
}
```

### Filter Graph for HDR → SDR + Scale

```rust
fn build_filter_graph(
    decoder: &decoder::Video,
    encoder: &encoder::Video,
    source: &MediaProbe,
) -> Result<filter::Graph> {
    let mut graph = filter::Graph::new();

    let args = format!(
        "video_size={}x{}:pix_fmt={}:time_base={}/{}:pixel_aspect={}/{}",
        decoder.width(), decoder.height(),
        decoder.format().descriptor().unwrap().name(),
        decoder.time_base().0, decoder.time_base().1,
        decoder.aspect_ratio().0, decoder.aspect_ratio().1,
    );

    graph.add(&filter::find("buffer").unwrap(), "in", &args)?;
    graph.add(&filter::find("buffersink").unwrap(), "out", "")?;

    let filter_spec = if source.is_hdr {
        // HDR → SDR + scale to 1080p
        format!(
            "zscale=t=linear:npl=100,format=gbrpf32le,\
             zscale=p=bt709:t=bt709:m=bt709:r=tv,format=yuv420p,\
             scale=w=1920:h=-2"
        )
    } else if decoder.width() > 1920 {
        // SDR downscale to 1080p
        "scale=w=1920:h=-2".to_string()
    } else {
        // Pass through
        "null".to_string()
    };

    graph.output("in", 0)?.input("out", 0)?.parse(&filter_spec)?;
    graph.validate()?;
    Ok(graph)
}
```

### Why in-process FFmpeg over subprocess

| Factor | Subprocess (`std::process::Command`) | In-process (`ffmpeg-the-third`) |
|--------|-------------------------------------|-------------------------------|
| Progress reporting | Parse stderr text (fragile) | Direct frame count / PTS access |
| Error handling | Exit code + stderr scraping | Typed Rust errors |
| Cancellation | Kill process (SIGTERM) | Drop encoder (immediate, clean) |
| Memory control | FFmpeg manages everything | Can control buffer sizes |
| Filter graph | CLI string (error-prone) | API objects (type-safe) |
| HW accel | CLI flags | API calls, can probe capabilities |
| Build complexity | FFmpeg binary must be installed | Links at compile time, can static-link |
| Frame interception | Not possible | Can inspect/modify decoded frames |

The subprocess approach is simpler for a v1 prototype. The in-process approach is better for production — it eliminates the ffmpeg binary dependency and gives fine-grained control. **Recommendation: start with subprocess for v1, migrate to `ffmpeg-the-third` for v2.**

---

## Profile B Contract (Universal)

Unchanged from previous spec. This is what the player requires for zero-copy HLS serving:

| Property | Requirement |
|----------|-------------|
| Container | MP4, moov before mdat (faststart) |
| Video | H.264 High Profile ≤ Level 4.1, yuv420p |
| Resolution | ≤ 1920×1080 (preserve aspect ratio) |
| Framerate | Preserved from source |
| Keyframes | Every 2 seconds (GOP = 2 × fps), no scene-cut insertion |
| HDR | Tone-mapped to SDR |
| Audio | AAC-LC stereo, 256 kbps, 48 kHz |
| Tracks | Exactly 1 video + 1 audio |
| Subtitles | None embedded (served separately) |
| Interleaving | Audio + video interleaved |

### FFmpeg CLI (v1 subprocess approach)

```bash
ffmpeg -i "{input}" \
  -map 0:v:0 -map 0:a:{selected_track} \
  -c:v libx264 \
  -preset medium \
  -crf 20 \
  -profile:v high \
  -level:v 4.1 \
  -pix_fmt yuv420p \
  -vf "scale=w='min(1920,iw)':h=-2" \
  -g {fps * 2} \
  -keyint_min {fps * 2} \
  -sc_threshold 0 \
  -c:a aac \
  -b:a 256k \
  -ac 2 \
  -ar 48000 \
  -movflags +faststart \
  -f mp4 \
  "{output}.mp4"
```

Add HDR tone mapping filter if source is HDR:

```bash
# Prepend to -vf for HDR10/HLG:
"zscale=t=linear:npl=100,format=gbrpf32le,zscale=p=bt709:t=bt709:m=bt709:r=tv,format=yuv420p,scale=w='min(1920,iw)':h=-2"

# For Dolby Vision (requires FFmpeg with libplacebo):
"libplacebo=tonemapping=bt.2390:colorspace=bt709:color_primaries=bt709:color_trc=bt709,format=yuv420p,scale=w='min(1920,iw)':h=-2"
```

### Hardware Acceleration

```bash
# NVIDIA NVENC
-hwaccel cuda -hwaccel_output_format cuda \
-c:v h264_nvenc -preset p4 -rc:v vbr -cq 22 \
-profile:v high -level:v 4.1

# Intel QSV
-hwaccel qsv \
-c:v h264_qsv -preset medium -global_quality 22 \
-profile:v high -level 41

# VAAPI (AMD/Intel Linux)
-hwaccel vaapi -hwaccel_device /dev/dri/renderD128 \
-hwaccel_output_format vaapi \
-c:v h264_vaapi -profile:v 100 -level 41
```

---

## Source Probing — Pure Rust

Probing runs at scan time for every file in the library. It must be fast and have no external dependencies. We use our own sf-media parser (already built for the player) plus symphonia for audio metadata.

```rust
/// Probed from the source file at scan time.
/// No FFmpeg dependency — pure Rust parsing.
struct MediaProbe {
    // Container
    container: Container,               // Mp4, Mkv, Avi, Ts, Other
    has_faststart: bool,                // moov before mdat (MP4 only)

    // Video
    video_codec: VideoCodec,            // H264, Hevc, Av1, Vp9, Other
    width: u32,
    height: u32,
    fps: f64,
    video_profile: Option<String>,      // "High", "Main", "Baseline"
    video_level: Option<u32>,           // 41 = 4.1
    bit_depth: u8,                      // 8, 10, 12
    color_primaries: Option<String>,    // "bt709", "bt2020"
    transfer_characteristics: Option<String>, // "smpte2084" (PQ), "arib-std-b67" (HLG)
    is_hdr: bool,
    hdr_type: Option<HdrType>,
    keyframe_interval_secs: f64,        // Average gap between sync samples

    // Audio (all tracks)
    audio_tracks: Vec<AudioTrack>,

    // Overall
    duration_secs: f64,
    file_size: u64,
    video_tracks: usize,
    audio_track_count: usize,
}

struct AudioTrack {
    index: usize,
    codec: AudioCodec,
    channels: u32,
    sample_rate: u32,
    language: Option<String>,
    title: Option<String>,
    is_default: bool,
}

enum HdrType { Hdr10, Hlg, DolbyVision, Hdr10Plus }
```

### What we parse ourselves vs symphonia

sf-media (our crate) handles:
- MP4: walk moov → trak → mdia → minf → stbl to get codec params, keyframe table (stss), durations (stts), faststart detection (moov offset < mdat offset)
- MKV: EBML header, TrackEntry elements for codec/resolution, Cues presence

symphonia handles:
- Audio track enumeration with language tags, codec detection
- Duration extraction from container metadata
- Format auto-detection (probe by magic bytes)

Combined, these give us everything ffprobe provides, without spawning a process.

---

## Data Model

### media_files — Dynamic, not fixed profiles

```sql
CREATE TABLE media_files (
    id              TEXT PRIMARY KEY,
    item_id         TEXT NOT NULL REFERENCES items(id) ON DELETE CASCADE,
    role            TEXT NOT NULL,       -- 'source', 'universal', 'extra'
    file_path       TEXT NOT NULL,
    file_size       INTEGER NOT NULL,
    container       TEXT NOT NULL,       -- 'mp4', 'mkv', 'avi', etc.
    video_codec     TEXT,
    audio_codec     TEXT,
    width           INTEGER,
    height          INTEGER,
    duration_ticks  INTEGER,
    bit_rate        INTEGER,
    is_hdr          BOOLEAN DEFAULT 0,
    serves_as_universal BOOLEAN DEFAULT 0, -- Source that already meets Profile B contract
    created_at      TEXT NOT NULL DEFAULT (datetime('now')),
    UNIQUE(item_id, role)
);

CREATE INDEX idx_media_files_item ON media_files(item_id);
```

Key change: `media_profile` ('A'/'B') becomes `role` ('source', 'universal', 'extra'). The `serves_as_universal` flag lets the player know it can build HLS segment maps from this source file without needing a separate universal file.

### media_streams — Unchanged

```sql
CREATE TABLE media_streams (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    media_file_id   TEXT NOT NULL REFERENCES media_files(id) ON DELETE CASCADE,
    stream_index    INTEGER NOT NULL,
    stream_type     TEXT NOT NULL,       -- 'Video', 'Audio', 'Subtitle'
    codec           TEXT NOT NULL,
    profile         TEXT,
    level           INTEGER,
    width           INTEGER,
    height          INTEGER,
    bit_rate        INTEGER,
    channels        INTEGER,
    sample_rate     INTEGER,
    language        TEXT,
    title           TEXT,
    is_default      BOOLEAN DEFAULT 0,
    is_forced       BOOLEAN DEFAULT 0,
    is_external     BOOLEAN DEFAULT 0
);
```

### conversion_jobs

```sql
CREATE TABLE conversion_jobs (
    id              TEXT PRIMARY KEY,
    item_id         TEXT NOT NULL REFERENCES items(id) ON DELETE CASCADE,
    source_file_id  TEXT NOT NULL REFERENCES media_files(id),
    status          TEXT NOT NULL DEFAULT 'queued',
    progress_pct    REAL DEFAULT 0.0,
    output_path     TEXT,
    error_message   TEXT,
    hw_accel_used   TEXT,               -- 'none', 'nvenc', 'qsv', 'vaapi'
    encode_fps      REAL,               -- Encoding speed (for UI)
    started_at      TEXT,
    completed_at    TEXT,
    created_at      TEXT NOT NULL DEFAULT (datetime('now'))
);

CREATE INDEX idx_conversion_jobs_status ON conversion_jobs(status);
```

Simplified: one job = one output file. No split A/B status. If the user wants to remux a source to MKV, that's a separate job type.

### items table changes

```sql
-- Items remain pure metadata. Remove any file-specific columns.
-- Canonical display info comes from the source media_file:
--   duration_ticks, resolution (e.g. '2160p'), video_codec, audio_codec
-- These are denormalized from the source media_file for fast queries.
```

---

## Conversion Pipeline

### Flow

```
Scanner discovers file
        │
        ▼
  Probe (pure Rust)
  Extract MediaProbe
        │
        ▼
  Insert media_file (role='source')
  Insert media_streams
        │
        ▼
  Qualify source ──── meets Profile B? ──── yes ──→ Set serves_as_universal=true
        │                                            Done. No conversion needed.
        no
        │
        ▼
  auto_convert enabled? ──── no ──→ Done. Source served via direct stream.
        │
        yes
        │
        ▼
  Queue conversion job
        │
        ▼
  Worker picks up job
  FFmpeg transcode → {cache_dir}/{item_id}/universal.mp4
        │
        ▼
  Probe output (pure Rust)
  Verify Profile B contract
        │
        ▼
  Insert media_file (role='universal')
  Insert media_streams for output
        │
        ▼
  Notify player to rebuild segment map for this item
```

### Audio Track Selection

For the universal file, select the best audio track from the source:

1. Default track if it's stereo AAC 48 kHz (can copy without re-encode)
2. First English stereo track
3. First English track (will be downmixed)
4. Default track (any language)
5. First track

### Conversion Worker

```rust
struct ConversionWorker {
    config: ConversionConfig,
    db: Database,
    semaphore: Arc<Semaphore>,  // Limits concurrency
}

impl ConversionWorker {
    async fn run_job(&self, job: ConversionJob) -> Result<()> {
        let _permit = self.semaphore.acquire().await?;

        self.db.update_job_status(job.id, "running").await?;

        let source = self.db.get_media_file(job.source_file_id).await?;
        let probe = probe_file(&source.file_path)?;

        let output_path = self.config.cache_dir
            .join(&job.item_id)
            .join("universal.mp4");
        tokio::fs::create_dir_all(output_path.parent().unwrap()).await?;

        let result = self.transcode(&source, &probe, &output_path, &job).await;

        match result {
            Ok(()) => {
                // Verify output
                let output_probe = probe_file(&output_path)?;
                verify_profile_b(&output_probe)?;

                // Register in database
                let file_id = self.db.insert_media_file(MediaFileRow {
                    item_id: job.item_id.clone(),
                    role: "universal".into(),
                    file_path: output_path.to_string_lossy().into(),
                    // ... fill from output_probe
                }).await?;

                self.db.update_job_status(job.id, "completed").await?;
            }
            Err(e) => {
                self.db.update_job_status_error(job.id, &e.to_string()).await?;
            }
        }
        Ok(())
    }
}
```

### Profile B Verification (pure Rust)

Reuses the player's MP4 moov parser. No FFmpeg needed.

```rust
fn verify_profile_b(probe: &MediaProbe) -> Result<(), Vec<String>> {
    let mut errors = Vec::new();

    if probe.container != Container::Mp4 {
        errors.push("Container is not MP4".into());
    }
    if !probe.has_faststart {
        errors.push("moov is not before mdat (no faststart)".into());
    }
    if probe.video_codec != VideoCodec::H264 {
        errors.push(format!("Video codec is {:?}, expected H.264", probe.video_codec));
    }
    if probe.width > 1920 {
        errors.push(format!("Width {} exceeds 1920", probe.width));
    }
    if probe.keyframe_interval_secs > 3.0 {
        errors.push(format!(
            "Keyframe interval {:.1}s exceeds 3.0s maximum",
            probe.keyframe_interval_secs
        ));
    }
    if probe.video_tracks != 1 {
        errors.push(format!("{} video tracks, expected 1", probe.video_tracks));
    }
    if probe.audio_track_count != 1 {
        errors.push(format!("{} audio tracks, expected 1", probe.audio_track_count));
    }
    if probe.is_hdr {
        errors.push("Output is still HDR (tone mapping failed?)".into());
    }

    if errors.is_empty() { Ok(()) } else { Err(errors) }
}
```

---

## Player Integration

The player needs to know which file to serve for a given item. The logic:

```rust
/// Determine which file the player should use for HLS serving.
fn resolve_hls_file(item_id: &str, db: &Database) -> Option<MediaFile> {
    // 1. Universal file exists? Use it.
    if let Some(f) = db.get_media_file_by_role(item_id, "universal") {
        return Some(f);
    }

    // 2. Source qualifies as universal? Use it.
    if let Some(f) = db.get_media_file_by_role(item_id, "source") {
        if f.serves_as_universal {
            return Some(f);
        }
    }

    // 3. No HLS-capable file. Player falls back to direct stream (range requests).
    None
}

/// Determine which file to use for direct stream / download.
fn resolve_direct_stream_file(item_id: &str, db: &Database) -> Option<MediaFile> {
    // Prefer source (higher quality), fall back to universal
    db.get_media_file_by_role(item_id, "source")
        .or_else(|| db.get_media_file_by_role(item_id, "universal"))
}
```

When the player merges into sceneforged, these become internal function calls rather than database queries across process boundaries.

---

## Library Manager (sceneforged core)

The converter is one subsystem of the library manager. Here's how they fit together:

```
sceneforged
├── scanner         # Watches library directories, discovers new/changed/removed files
├── prober          # Pure Rust media probe (sf-media + symphonia)
├── metadata        # Fetches title, artwork, ratings from external sources
├── converter       # FFmpeg transcoding pipeline (this document)
├── database        # SQLite (items, media_files, media_streams, conversion_jobs)
├── api             # HTTP API for the web UI and player
└── (player)        # Merged later: HLS serving, segment maps, direct stream
```

### Scanner → Converter Flow

```rust
impl Scanner {
    async fn on_file_discovered(&self, path: &Path) {
        // 1. Probe
        let probe = match probe_file(path) {
            Ok(p) => p,
            Err(e) => { warn!("Skipping {}: {}", path.display(), e); return; }
        };

        // 2. Match to existing item or create new
        let item_id = self.match_or_create_item(path, &probe).await;

        // 3. Register source file
        let file_id = self.db.insert_media_file(MediaFileRow {
            item_id: item_id.clone(),
            role: "source".into(),
            file_path: path.to_string_lossy().into(),
            serves_as_universal: qualify_source(&probe).serves_as_universal,
            // ... fill from probe
        }).await;

        // 4. Register streams
        for track in &probe.audio_tracks {
            self.db.insert_media_stream(/* ... */).await;
        }

        // 5. Queue conversion if needed
        let qual = qualify_source(&probe);
        if qual.needs_conversion && self.config.auto_convert {
            self.converter.queue(ConversionJob {
                item_id,
                source_file_id: file_id,
                // ...
            }).await;
        }
    }
}
```

### API Endpoints

```
POST   /api/convert/{item_id}              # Queue conversion
DELETE /api/convert/{item_id}              # Cancel running conversion
GET    /api/convert/{item_id}/status       # Job status + progress
GET    /api/convert/queue                  # List all jobs (with filters)
POST   /api/convert/queue/bulk             # Queue all items needing conversion

GET    /api/items/{item_id}/files          # List all media_files for an item
GET    /api/library/stats                  # How many items have universal files, etc.
```

---

## Configuration

```toml
[library]
paths = ["/media/movies", "/media/tv"]    # Watched directories
scan_interval_secs = 300                   # Rescan every 5 minutes

[conversion]
cache_dir = "/data/sceneforged/cache"      # Where universal files are stored
max_parallel = 1                           # Concurrent transcode jobs
auto_convert = true                        # Queue conversion on import
ffmpeg_path = "ffmpeg"                     # v1 subprocess mode
hw_accel = "auto"                          # auto | none | nvenc | qsv | vaapi

# Profile B quality
crf = 20
preset = "medium"
audio_bitrate = "256k"
max_resolution = 1920                      # Cap width at 1920 (1080p)

[player]
# Player config will go here when merged
```

---

## Implementation Phases

### Phase 1: Probe + Scan + Database (pure Rust, no FFmpeg)
- sf-media crate: MP4 moov parser, MKV EBML parser (already designed for player)
- symphonia integration for audio track enumeration
- `MediaProbe` struct and `qualify_source()` logic
- `media_files` + `media_streams` tables
- Scanner that discovers files, probes, and registers them
- Source qualification: detect files that already meet Profile B contract

### Phase 2: Converter — Subprocess (FFmpeg CLI)
- Build FFmpeg command strings from MediaProbe + config
- Spawn FFmpeg subprocess, parse stderr for progress
- Job queue with configurable parallelism (tokio semaphore)
- Profile B verification after conversion (pure Rust moov check)
- Register output in media_files
- API endpoints for trigger/status/cancel
- HW accel detection (probe available encoders)

### Phase 3: Player Merge
- Move player serving logic into sceneforged
- Segment map builder reads from media_files table
- resolve_hls_file() and resolve_direct_stream_file() become internal
- Single process, single database

### Phase 4: Converter — In-process FFmpeg (optional, v2)
- Replace subprocess with `ffmpeg-the-third` linked bindings
- Direct frame-level access for progress, cancellation, error handling
- Potentially use muxide for MP4 output (pure Rust muxer)
- Potentially use gainforge for HDR tone mapping (pure Rust)

---

## Crate Dependencies Summary

### sceneforged (library manager + converter)

```toml
# Core
tokio = { version = "1", features = ["full"] }
axum = "0.8"
rusqlite = { version = "0.32", features = ["bundled"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Media probing (pure Rust)
symphonia = { version = "0.5", features = ["all"] }
bytes = "1"

# Conversion (Phase 2: subprocess)
# No additional deps — uses std::process::Command + tokio::process::Command

# Conversion (Phase 4: in-process, optional)
# ffmpeg-the-third = "2"

# Async runtime + utilities
notify = "7"              # Filesystem watcher for scanner
dashmap = "6"             # Concurrent maps
uuid = { version = "1", features = ["v4"] }
chrono = "0.4"
tracing = "0.1"
anyhow = "1"
```

### sf-media (shared crate, pure Rust)

Used by both the player and the library manager:

```toml
# Zero external dependencies for the core parser
bytes = "1"
thiserror = "2"
```

This crate contains:
- MP4 atom walking + moov/stbl parsing
- MKV EBML parsing + Cues detection
- Faststart detection
- Keyframe interval calculation
- Codec parameter extraction (avcC, hvcC, esds)
- fMP4 serialization (for player's HLS)
- The `MediaProbe` struct and qualification logic